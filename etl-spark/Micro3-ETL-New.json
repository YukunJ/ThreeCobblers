{"paragraphs":[{"text":"%livy2.pyspark\n#df_Raw = spark.read.json(\"wasb://ccgroupproject-2022-03-19t14-47-33-853z@ccgroupprojechdistorage.blob.core.windows.net/user/livy/cleanData.json\")\n#df_Raw = spark.read.json(\"wasb://ccgroupproject-2022-03-19t14-47-33-853z@ccgroupprojechdistorage.blob.core.windows.net/user/livy/microservice3_ref.txt\")","user":"anonymous","dateUpdated":"2022-03-21T23:11:57+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647893362610_0011<br/>Spark WebUI: <a href=\"http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/\">http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/</a>"}]},"apps":[],"jobName":"paragraph_1647893792760_1813674894","id":"20220320-171901_1247104049","dateCreated":"2022-03-21T20:16:32+0000","dateStarted":"2022-03-21T23:06:31+0000","dateFinished":"2022-03-21T23:07:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:16431"},{"text":"%livy2.pyspark\nimport locale\nlocale.setlocale(locale.LC_ALL,'en_US.UTF-8'); # set the encoding for UTF-8 functionality\nfrom pyspark.sql.functions import from_json, col, size, explode, lower, desc, when, isnull, log, to_date, to_timestamp, countDistinct, row_number, collect_list, concat_ws, udf\nfrom pyspark.sql import Window\nimport time\n#spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n#spark.conf.set(\"spark.sql.adaptive.skewJoin.enabled\", \"true\")\n#spark.conf.set(\"spark.default.parallelism\",500)\n#spark.conf.set(\"spark.sql.shuffle.partitions\", 1000)","user":"anonymous","dateUpdated":"2022-03-21T23:06:41+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647893362610_0011<br/>Spark WebUI: <a href=\"http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/\">http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/</a>"}]},"apps":[],"jobName":"paragraph_1647893792767_1470046979","id":"20220320-181416_1283187381","dateCreated":"2022-03-21T20:16:32+0000","dateStarted":"2022-03-21T23:06:41+0000","dateFinished":"2022-03-21T23:07:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16432"},{"text":"%livy2.pyspark\ndf_ref = df_Raw\ncolumns = df_ref.columns\n\n#find the contact tweet\ndf_contact = df_ref.filter(~(isnull(df_ref.in_reply_to_user_id) & isnull(df_ref.retweeted_status)))\n\n#extract user id from user\ndf_contact = df_contact.withColumn(\"user_id\", df_contact.user[\"id\"])\n\n#extract retweeted_user from retweeted_status\ndf_contact = df_contact.withColumn('retweeted_user', when(isnull(df_contact.retweeted_status), None).otherwise(df_contact.retweeted_status[\"user\"]))\n\n#extract retweeted_user_id from retweeted_user\ndf_contact = df_contact.withColumn('retweeted_user_id', when(isnull(df_contact.retweeted_user), None).otherwise(df_contact.retweeted_user[\"id\"]))\n\n#only keep id fields\ndf_contact = df_contact[[\"user_id\", \"in_reply_to_user_id\", \"retweeted_user_id\"]]\n\n#find the reply tweet, duplicate them, since they contribute 2 points to the score\ndf_reply = df_contact.filter(~isnull(df_contact.in_reply_to_user_id))","user":"anonymous","dateUpdated":"2022-03-21T23:06:53+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647893362610_0011<br/>Spark WebUI: <a href=\"http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/\">http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/</a>"}]},"apps":[],"jobName":"paragraph_1647893792768_-1658320822","id":"20220320-215835_332326814","dateCreated":"2022-03-21T20:16:32+0000","dateStarted":"2022-03-21T23:07:17+0000","dateFinished":"2022-03-21T23:07:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16433"},{"text":"%livy2.pyspark\n#========================================================Interaction Score========================================================================#\ndf_contact_more_reply = df_contact.unionByName(df_reply)\n\n#combine in_reply_to_user_id with retweeted_user_id to form contact_user_id\ndf_contact_more_reply = df_contact_more_reply.withColumn('contact_user_id', when(isnull(df_contact_more_reply.retweeted_user_id), df_contact_more_reply.in_reply_to_user_id).otherwise(df_contact_more_reply.retweeted_user_id))[[\"user_id\", \"contact_user_id\"]]\n\n#find contact tweet involving only one user\ndf_contact_more_reply_self = df_contact_more_reply.filter(df_contact_more_reply.user_id == df_contact_more_reply.contact_user_id)\n\n#find contact tweet involving two users\ndf_contact_more_reply_other = df_contact_more_reply.filter(~(df_contact_more_reply.user_id == df_contact_more_reply.contact_user_id))\n\n#for row A, B, make a row B, A, since we want to store score between A and B two times to speed up query, no need to do this for contact tweet involving only one user\ndf_contact_more_reply_other_all = df_contact_more_reply_other.unionByName(df_contact_more_reply_other.rdd.toDF([\"contact_user_id\", \"user_id\"]))\n\n#glue contact user together\ndf_contact_all = df_contact_more_reply_other_all.unionByName(df_contact_more_reply_self)\n\n# PARTITION\ndf_contact_all = df_contact_all.repartition(1000, \"user_id\", \"contact_user_id\")\n\n#find the count\ndf_interaction = df_contact_all.groupby(\"user_id\", \"contact_user_id\").count()\n\n#compute the score\ndf_interaction_score = df_interaction.withColumn(\"interaction_score\", log(1 + df_interaction[\"count\"])).drop(\"count\")\n","user":"anonymous","dateUpdated":"2022-03-21T23:06:55+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647893362610_0011<br/>Spark WebUI: <a href=\"http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/\">http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/</a>"}]},"apps":[],"jobName":"paragraph_1647893792768_-2038349398","id":"20220320-151509_920033301","dateCreated":"2022-03-21T20:16:32+0000","dateStarted":"2022-03-21T23:07:17+0000","dateFinished":"2022-03-21T23:07:22+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16434"},{"text":"%livy2.pyspark\n#========================================================Alternative way to calculate hashtag score========================================================================#\nrawDf = df_Raw\n\n# load in the blacklist of popular hashtag\nrawPopular = sc.textFile(\"popular_hashtags.txt\")\npopular_tags = rawPopular.collect()\n\n# extract out the nested hashtag field from the entity field\ndf_hashtags_out = rawDf.withColumn(\"hashtags\", col(\"entities.hashtags\"))\n\n# explode out the hashtag list into individual hashtag\ndf_hashtags_explode = df_hashtags_out.withColumn(\"explode_tag\", explode(\"hashtags\"))\n\n# transform all tags to lower cases\ndf_hashtags_text = df_hashtags_explode.withColumn(\"tag_text\", lower(col(\"explode_tag.text\")))\n\n# rename to user_id\ndf_hash_tags_text_tags = df_hashtags_text\\\n            .withColumn(\"user_id_hash\", col(\"user.id\"))\n            \n# select only relevant fields\ndf_tags = df_hash_tags_text_tags.select(col(\"user_id_hash\"), col(\"tag_text\"))\n\n# filter out blacklist popular tags\ndf_tags_filtered = df_tags.filter(~col(\"tag_text\").isin(popular_tags))\n\n#generating mapping from user id to list of hashtag\ndf_tags_list = df_tags_filtered.groupby(\"user_id_hash\").agg(collect_list('tag_text').alias('tag_list')).cache()\n\n#add user tag list\ndf_interaction_score_tags = df_interaction_score.join(df_tags_list,\\\n                        df_interaction_score.user_id == df_tags_list.user_id_hash,\\\n                        how = \"left\").drop(\"user_id_hash\")\n                        \ndf_interaction_score_tags = df_interaction_score_tags.withColumnRenamed(\"tag_list\", \"user_tag_list\")\n\n#add contact user tag list\ndf_interaction_score_tags = df_interaction_score_tags.join(df_tags_list,\\\n                        df_interaction_score.contact_user_id == df_tags_list.user_id_hash,\\\n                        how = \"left\").drop(\"user_id_hash\")\n                        \ndf_interaction_score_tags = df_interaction_score_tags.withColumnRenamed(\"tag_list\", \"contact_user_tag_list\")","user":"anonymous","dateUpdated":"2022-03-21T23:06:57+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647893362610_0011<br/>Spark WebUI: <a href=\"http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/\">http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/</a>"}]},"apps":[],"jobName":"paragraph_1647893792769_-1538126797","id":"20220320-204839_1256238007","dateCreated":"2022-03-21T20:16:32+0000","dateStarted":"2022-03-21T23:07:18+0000","dateFinished":"2022-03-21T23:07:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16435"},{"text":"%livy2.pyspark\n#define funtion used to compute hashtag score\nimport math\ndef hashtag_score(user_tag_list, contact_user_tag_list):\n    \n    if user_tag_list is None or contact_user_tag_list is None:\n         return 1.0\n         \n    user_tag_counter = {}\n    \n    for tag in user_tag_list:\n        if tag in user_tag_counter:\n            user_tag_counter[tag] += 1\n        else:\n            user_tag_counter[tag] = 1\n            \n    contact_user_counter = {}\n    \n    for tag in contact_user_tag_list:\n        if tag in contact_user_counter:\n            contact_user_counter[tag] += 1\n        else:\n            contact_user_counter[tag] = 1\n            \n    common_keys = set(user_tag_counter.keys()).intersection(set(contact_user_counter.keys()))\n    \n    common_tag_count = 0        \n    for tag in common_keys:\n        common_tag_count += user_tag_counter[tag]\n        common_tag_count += contact_user_counter[tag]\n    \n    if common_tag_count > 10:\n        return 1.0 + math.log(1 + common_tag_count - 10)\n    else: \n        return 1.0","user":"anonymous","dateUpdated":"2022-03-21T23:06:59+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647893362610_0011<br/>Spark WebUI: <a href=\"http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/\">http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/</a>"}]},"apps":[],"jobName":"paragraph_1647903633707_-1635675275","id":"20220321-230033_1282287123","dateCreated":"2022-03-21T23:00:33+0000","dateStarted":"2022-03-21T23:07:23+0000","dateFinished":"2022-03-21T23:07:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16436"},{"text":"%livy2.pyspark\n#compute the hash score\nfrom pyspark.sql.functions import udf\nimport pyspark.sql.types as T\n\nhashtag_score_udf = udf(hashtag_score, T.DoubleType())\ndf_interaction_score_hashtag_score = df_interaction_score_tags.withColumn(\"hashtag_score\", when(col(\"user_id\") != col(\"contact_user_id\"), hashtag_score_udf(df_interaction_score_tags.user_tag_list, df_interaction_score_tags.contact_user_tag_list)).otherwise(1.0))","user":"anonymous","dateUpdated":"2022-03-21T23:07:02+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647893362610_0011<br/>Spark WebUI: <a href=\"http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/\">http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/</a>"}]},"apps":[],"jobName":"paragraph_1647903668419_946681984","id":"20220321-230108_1711538343","dateCreated":"2022-03-21T23:01:08+0000","dateStarted":"2022-03-21T23:07:28+0000","dateFinished":"2022-03-21T23:07:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16437"},{"text":"%livy2.pyspark\n#========================================================Join Interaction&Hashtag Score========================================================================#\ndf_product_score = df_interaction_score_hashtag_score.withColumn(\"product_score\", df_interaction_score_hashtag_score.hashtag_score * df_interaction_score_hashtag_score.interaction_score).select(\"user_id\", \"contact_user_id\", \"product_score\")","user":"anonymous","dateUpdated":"2022-03-21T23:07:03+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647893362610_0011<br/>Spark WebUI: <a href=\"http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/\">http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/</a>"}]},"apps":[],"jobName":"paragraph_1647903690325_-150147521","id":"20220321-230130_245572930","dateCreated":"2022-03-21T23:01:30+0000","dateStarted":"2022-03-21T23:07:29+0000","dateFinished":"2022-03-21T23:07:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16438"},{"text":"%livy2.pyspark\n#========================================================Latest Contact Tweet Between Users========================================================================#\n#read the dataset\ndf_ref = df_Raw\n\ndf_ref_clean = df_ref.withColumn(\"user_id\", df_ref.user[\"id\"]).withColumn(\"tweet_id\", col(\"id\")) \\\n               .withColumn(\"ts\", to_timestamp(col(\"created_at\"), \"EEE MMM dd HH:mm:ss Z yyyy\"))\n               \n#extract retweeted_user from retweeted_status\ndf_ref_clean = df_ref_clean.withColumn('retweeted_user', when(isnull(df_ref_clean.retweeted_status), None).otherwise(df_ref_clean.retweeted_status[\"user\"]))\n\n#extract retweeted_user_id from retweeted_user\ndf_ref_clean = df_ref_clean.withColumn('retweeted_user_id', when(isnull(df_ref_clean.retweeted_user), None).otherwise(df_ref_clean.retweeted_user[\"id\"]))[[\"user_id\", \"in_reply_to_user_id\", \"retweeted_user_id\", \"text\", \"ts\", \"tweet_id\"]]\n\ndf_reply = df_ref_clean.filter(~isnull(df_ref_clean.in_reply_to_user_id))\ndf_reply = df_reply.withColumn('contact_user_id', df_reply['in_reply_to_user_id'])[['user_id','contact_user_id', 'text', 'ts', 'tweet_id']]\n\n\n#find contact tweet involving only one user\ndf_reply_self = df_reply.filter(df_reply.user_id == df_reply.contact_user_id)\n\n#find contact tweet involving two users\ndf_reply_other = df_reply.filter(~(df_reply.user_id == df_reply.contact_user_id))\n\n#for row A, B, make a row B, A, since we want to store score between A and B two times to speed up query, no need to do this for contact tweet involving only one user\ndf_reply_all = df_reply_other.unionByName(df_reply_other.rdd.toDF(['contact_user_id', 'user_id', 'text', 'ts', 'tweet_id']))\n\n#glue contact user together\ndf_reply_all = df_reply_all.unionByName(df_reply_self)\n\n#PARTITION\ndf_reply_all = df_reply_all.repartition(\"user_id\", \"contact_user_id\")\nw = Window.partitionBy(\"user_id\", \"contact_user_id\").orderBy(col(\"ts\").desc(), col(\"tweet_id\").desc())\ndf_reply_latest = df_reply_all.withColumn('group_rowrank', row_number().over(w))\\\n                .filter(col(\"group_rowrank\") == 1)\\\n                .drop(\"group_rowrank\")\n    \ndf_reply_latest = df_reply_latest.withColumn(\"ts_reply\", df_reply_latest[\"ts\"]) \\\n                                .withColumn(\"id_reply\", df_reply_latest[\"tweet_id\"]) \\\n                                .withColumn(\"latest_reply\", df_reply_latest.text) \\\n                                .withColumn(\"user_id_reply\", df_reply_latest.user_id) \\\n                                .withColumn(\"contact_user_id_reply\", df_reply_latest.contact_user_id) \\\n                                .drop(\"ts\", \"tweet_id\", \"user_id\", \"contact_user_id\", \"text\")\n\n\ndf_retweet = df_ref_clean.filter(~isnull(df_ref_clean['retweeted_user_id']))\ndf_retweet = df_retweet.withColumn('contact_user_id', df_retweet['retweeted_user_id'])[['user_id','contact_user_id', 'text', 'ts', 'tweet_id']]\n\n\n#find contact tweet involving only one user\ndf_retweet_self = df_retweet.filter(df_retweet.user_id == df_retweet.contact_user_id)\n\n#find contact tweet involving two users\ndf_retweet_other = df_retweet.filter(~(df_retweet.user_id == df_retweet.contact_user_id))\n\n#for row A, B, make a row B, A, since we want to store score between A and B two times to speed up query, no need to do this for contact tweet involving only one user\ndf_retweet_all = df_retweet_other.unionByName(df_retweet_other.rdd.toDF(['contact_user_id', 'user_id', 'text', 'ts', 'tweet_id']))\n\n#PARTITION\ndf_retweet_all = df_retweet_all.repartition(\"user_id\", \"contact_user_id\")\n#glue contact user together\ndf_retweet_all = df_retweet_all.unionByName(df_retweet_self)\n\nw = Window.partitionBy(\"user_id\", \"contact_user_id\").orderBy(col(\"ts\").desc(), col(\"tweet_id\").desc())\ndf_retweet_latest = df_retweet_all.withColumn('group_rowrank', row_number().over(w))\\\n                .filter(col(\"group_rowrank\") == 1)\\\n                .drop(\"group_rowrank\")\n\n\n\ndf_retweet_latest = df_retweet_latest.withColumn(\"ts_retweet\", df_retweet_latest[\"ts\"]) \\\n                                .withColumn(\"id_retweet\", df_retweet_latest[\"tweet_id\"]) \\\n                                .withColumn(\"latest_retweet\", df_retweet_latest.text) \\\n                                .withColumn(\"user_id_retweet\", df_retweet_latest.user_id) \\\n                                .withColumn(\"contact_user_id_retweet\", df_retweet_latest.contact_user_id) \\\n                                .drop(\"ts\", \"tweet_id\", \"user_id\", \"contact_user_id\", \"text\")","user":"anonymous","dateUpdated":"2022-03-21T23:07:06+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647893362610_0011<br/>Spark WebUI: <a href=\"http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/\">http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/</a>"}]},"apps":[],"jobName":"paragraph_1647893792771_-1012713649","id":"20220320-151949_168924594","dateCreated":"2022-03-21T20:16:32+0000","dateStarted":"2022-03-21T23:07:30+0000","dateFinished":"2022-03-21T23:07:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16439"},{"text":"%livy2.pyspark\nstatic_table = df_product_score.join(df_reply_latest, (df_interaction_score.user_id == df_reply_latest.user_id_reply) & (df_interaction_score.contact_user_id == df_reply_latest.contact_user_id_reply), how='left')\n                                \nstatic_table = static_table.join(df_retweet_latest, (static_table.user_id == df_retweet_latest.user_id_retweet) & (static_table.contact_user_id == df_retweet_latest.contact_user_id_retweet), how='left') \\\n                                .drop(\"user_id_reply\", \"contact_user_id_reply\", \"user_id_retweet\",\"contact_user_id_retweet\")\n\nstatic_table = static_table.withColumn(\"both_latest\",  \\\n                when(isnull(static_table.ts_retweet), static_table[\"latest_reply\"]) \\\n                    .otherwise(when(isnull(static_table.ts_reply), static_table[\"latest_retweet\"]) \\\n                        .otherwise(when(static_table.ts_reply > static_table.ts_retweet, static_table[\"latest_reply\"]) \\\n                            .otherwise(when(static_table.ts_reply < static_table.ts_retweet, static_table[\"latest_retweet\"]) \\\n                                .otherwise(when(static_table.id_reply < static_table.id_retweet, static_table[\"latest_retweet\"]) \\\n                                    .otherwise(static_table[\"latest_reply\"]) \\\n                                ) \\\n                            ) \\\n                        ) \\\n                    ) \\\n                )\\\n                .drop(\"interaction_score\", \"ts_reply\", \"id_reply\", \"ts_retweet\", \"id_retweet\", \"user_id_tweet\", \"contact_user_id_tweet\") \\\n                .fillna(value = \"\", subset = [\"latest_retweet\", \"latest_reply\"])","user":"anonymous","dateUpdated":"2022-03-21T23:07:09+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647893362610_0011<br/>Spark WebUI: <a href=\"http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/\">http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/</a>"}]},"apps":[],"jobName":"paragraph_1647893792772_-1535116735","id":"20220320-194219_1368245026","dateCreated":"2022-03-21T20:16:32+0000","dateStarted":"2022-03-21T23:07:31+0000","dateFinished":"2022-03-21T23:07:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16440"},{"text":"%livy2.pyspark\n#========================================================Export to CSV File========================================================================#\nimport csv\nfrom StringIO import StringIO\ndef csv_string_for_row(row):\n    sio = StringIO()\n    csv.writer(sio, quoting=csv.QUOTE_ALL).writerow([unicode(elem).encode('utf-8') for elem in row])\n    value = sio.getvalue()\n    sio.close()\n    return value\nstatic_table.rdd.map(csv_string_for_row).saveAsTextFile('static_table.csv')\n","user":"anonymous","dateUpdated":"2022-03-21T23:07:11+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647893362610_0011<br/>Spark WebUI: <a href=\"http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/\">http://hn1-threec.zmett2kg2gmetjlajobnggh0ze.bx.internal.cloudapp.net:8088/proxy/application_1647893362610_0011/</a>"}]},"apps":[],"jobName":"paragraph_1647893792773_-756779963","id":"20220320-152043_1036102372","dateCreated":"2022-03-21T20:16:32+0000","dateStarted":"2022-03-21T23:07:36+0000","dateFinished":"2022-03-21T23:08:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16441"},{"text":"%livy2.pyspark\n#========================================================User Table========================================================================#\nimport locale\nlocale.setlocale(locale.LC_ALL,'en_US.UTF-8'); # set the encoding for Lower() functionality\nfrom pyspark.sql.functions import from_json, col, size, explode, lower, desc, when, log, to_date, to_timestamp, countDistinct, row_number\nfrom pyspark.sql import Window\n\nrawDf = df_Raw\n\n# take out the sender's user information\nuserDf = rawDf\\\n    .withColumn(\"tweet_id\", col(\"id\"))\\\n    .withColumn(\"ts\", to_timestamp(col(\"created_at\"), \"EEE MMM dd HH:mm:ss Z yyyy\"))\\\n    .withColumn(\"user_id\", col(\"user.id\"))\\\n    .withColumn(\"latest_screen_name\", col(\"user.screen_name\"))\\\n    .withColumn(\"latest_description\", col(\"user.description\"))\\\n    .select(\"tweet_id\", \"ts\", \"user_id\", \"latest_screen_name\", \"latest_description\")\n\n# take out the optionally retweet information\nretweetUserDf = rawDf.filter(~isnull(col(\"retweeted_status\")))\\\n                    .withColumn(\"tweet_id\", col(\"retweeted_status.id\"))\\\n                    .withColumn(\"ts\", to_timestamp(col(\"created_at\"), \"EEE MMM dd HH:mm:ss Z yyyy\"))\\\n                    .withColumn(\"user_id\", col(\"retweeted_status.user.id\"))\\\n                    .withColumn(\"latest_screen_name\", col(\"retweeted_status.user.screen_name\"))\\\n                    .withColumn(\"latest_description\", col(\"retweeted_status.user.description\"))\\\n                    .select(\"tweet_id\", \"ts\", \"user_id\", \"latest_screen_name\", \"latest_description\")\n\n# replace NULL description by empty string\nuserDf = userDf.fillna(value = \"\", subset = [\"latest_description\"])\nretweetUserDf = retweetUserDf.fillna(value = \"\", subset = [\"latest_description\"])\n\n# union the two dataframe\ntotal_user = userDf.unionByName(retweetUserDf)\n\n# partition by user_id and take the latest information based on descending timestamp, and then tweet_id for breaking tie\nw = Window.partitionBy(\"user_id\").orderBy(col(\"ts\").desc(), col(\"tweet_id\").desc())\nuser_info = total_user\\\n                .withColumn('group_rowrank', row_number().over(w))\\\n                .filter(col(\"group_rowrank\") == 1)\\\n                .drop(\"group_rowrank\", \"tweet_id\", \"ts\")","user":"anonymous","dateUpdated":"2022-03-21T20:16:32+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647802397257_0014<br/>Spark WebUI: <a href=\"http://hn1-cloud.pn4kh1fcooyenmbbmfayomuvka.bx.internal.cloudapp.net:8088/proxy/application_1647802397257_0014/\">http://hn1-cloud.pn4kh1fcooyenmbbmfayomuvka.bx.internal.cloudapp.net:8088/proxy/application_1647802397257_0014/</a>"}]},"apps":[],"jobName":"paragraph_1647893792774_-1835160346","id":"20220320-152052_841981029","dateCreated":"2022-03-21T20:16:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16442"},{"text":"%livy2.pyspark\n#========================================================Export to CSV File========================================================================#\nimport csv\nfrom StringIO import StringIO\ndef csv_string_for_row(row):\n    sio = StringIO()\n    csv.writer(sio, quoting=csv.QUOTE_ALL).writerow([unicode(elem).encode('utf-8') for elem in row])\n    value = sio.getvalue()\n    sio.close()\n    return value\nuser_info.rdd.map(csv_string_for_row).saveAsTextFile('user_info.csv')\n","user":"anonymous","dateUpdated":"2022-03-21T20:16:32+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647802397257_0014<br/>Spark WebUI: <a href=\"http://hn1-cloud.pn4kh1fcooyenmbbmfayomuvka.bx.internal.cloudapp.net:8088/proxy/application_1647802397257_0014/\">http://hn1-cloud.pn4kh1fcooyenmbbmfayomuvka.bx.internal.cloudapp.net:8088/proxy/application_1647802397257_0014/</a>"}]},"apps":[],"jobName":"paragraph_1647893792775_-412576400","id":"20220320-152054_1602739035","dateCreated":"2022-03-21T20:16:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16443"},{"text":"%livy2.pyspark\n#========================================================Dynamic Table========================================================================#\ndf_ref = df_Raw\n\n#find the contact tweet\ndf_contact = df_ref.filter(~(isnull(df_ref.in_reply_to_user_id) & isnull(df_ref.retweeted_status)))\n\n#extract user id from user\ndf_contact = df_contact.withColumn(\"user_id\", df_contact.user[\"id\"])\n\n#extract retweeted_user from retweeted_status\ndf_contact = df_contact.withColumn('retweeted_user', when(isnull(df_contact.retweeted_status), None).otherwise(df_contact.retweeted_status[\"user\"]))\n\n#extract retweeted_user_id from retweeted_user\ndf_contact = df_contact.withColumn('retweeted_user_id', when(isnull(df_contact.retweeted_user), None).otherwise(df_contact.retweeted_user[\"id\"]))\n\n#extract hashtag list\ndf_contact = df_contact.withColumn(\"hashTagList\", df_contact.entities[\"hashtags\"])\n\n# explode out the hashtag list into individual hashtag\ndf_contact_explode = df_contact.withColumn(\"explode_tag\", explode(\"hashTagList\"))\n\n# transform all tags to lower cases\ndf_contact_hashtag_text = df_contact_explode.withColumn(\"tag_text\", lower(df_contact_explode.explode_tag.text))\n\ndf_contact_hash_string = df_contact_hashtag_text.groupby(\"id\").agg(collect_list('tag_text').alias('tag_list')).withColumn(\"tags\", concat_ws(\"#\", col(\"tag_list\")))\n\ndf_content_tags = df_contact.join(df_contact_hash_string, 'id', 'left')[['user_id', 'in_reply_to_user_id', 'retweeted_user_id', 'text', \"tags\"]]\n\ndf_content_tags = df_content_tags.withColumn(\"contact_user_id\", when(isnull(df_content_tags.retweeted_user_id), df_content_tags.in_reply_to_user_id).otherwise(df_content_tags.retweeted_user_id))\n\ndf_content_tags = df_content_tags.withColumn(\"is_reply\", when(isnull(df_content_tags.retweeted_user_id), True).otherwise(False))\n\ndf_content_tags = df_content_tags[['user_id', 'contact_user_id', 'is_reply', 'text', \"tags\"]]\n\n#find contact tweet involving only one user\ndf_content_tags_self = df_content_tags.filter(df_content_tags.user_id == df_content_tags.contact_user_id)\n\n#find contact tweet involving two users\ndf_content_tags_other = df_content_tags.filter(~(df_content_tags.user_id == df_content_tags.contact_user_id))\n\ndf_content_tags_other_reverse = df_content_tags_other.rdd.toDF([\"contact_user_id\", \"user_id\", \"is_reply\", \"text\", \"tags\"])\n\n#for row A, B, make a row B, A, since we want to store score between A and B two times to speed up query, no need to do this for contact tweet involving only one user\ndf_content_tags_other_all = df_content_tags_other.unionByName(df_content_tags_other_reverse)\n\n#glue contact user together\ndf_content_tags_all = df_content_tags_other_all.unionByName(df_content_tags_self)\n\ndynamic_table = df_content_tags_all\\\n                .withColumnRenamed(\"user_id\", \"sender\")\\\n                .withColumnRenamed(\"contact_user_id\", \"receiver\")\\\n                .withColumnRenamed(\"text\", \"content\")\\\n                [[\"is_reply\", \"content\", \"tags\", \"sender\", \"receiver\"]]","user":"anonymous","dateUpdated":"2022-03-21T20:16:32+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647802397257_0014<br/>Spark WebUI: <a href=\"http://hn1-cloud.pn4kh1fcooyenmbbmfayomuvka.bx.internal.cloudapp.net:8088/proxy/application_1647802397257_0014/\">http://hn1-cloud.pn4kh1fcooyenmbbmfayomuvka.bx.internal.cloudapp.net:8088/proxy/application_1647802397257_0014/</a>"}]},"apps":[],"jobName":"paragraph_1647893792775_-663716874","id":"20220320-152055_2057850755","dateCreated":"2022-03-21T20:16:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16444"},{"text":"%livy2.pyspark\n#========================================================Export to CSV File========================================================================#\nimport csv\nfrom StringIO import StringIO\ndef csv_string_for_row(row):\n    sio = StringIO()\n    csv.writer(sio, quoting=csv.QUOTE_ALL).writerow([unicode(elem).encode('utf-8') for elem in row])\n    value = sio.getvalue()\n    sio.close()\n    return value\ndynamic_table.rdd.map(csv_string_for_row).saveAsTextFile('dynamic_table.csv')","user":"anonymous","dateUpdated":"2022-03-21T20:16:32+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647802397257_0014<br/>Spark WebUI: <a href=\"http://hn1-cloud.pn4kh1fcooyenmbbmfayomuvka.bx.internal.cloudapp.net:8088/proxy/application_1647802397257_0014/\">http://hn1-cloud.pn4kh1fcooyenmbbmfayomuvka.bx.internal.cloudapp.net:8088/proxy/application_1647802397257_0014/</a>"}]},"apps":[],"jobName":"paragraph_1647893792776_-1746627370","id":"20220320-152056_1270138001","dateCreated":"2022-03-21T20:16:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16445"}],"name":"Micro3NewHashtagScore","id":"2H13PC7SM","noteParams":{},"noteForms":{},"angularObjects":{"livy2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}