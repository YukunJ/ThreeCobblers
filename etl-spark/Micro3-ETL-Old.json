{"paragraphs":[{"text":"%livy2.pyspark\ndf_Raw = spark.read.json(\"wasb://ccgroupproject-2022-03-19t14-47-33-853z@ccgroupprojechdistorage.blob.core.windows.net/user/livy/cleanData.json\")","user":"anonymous","dateUpdated":"2022-03-21T23:56:40+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647903470178_0004<br/>Spark WebUI: <a href=\"http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/\">http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/</a>"}]},"apps":[],"jobName":"paragraph_1647906974465_1685744767","id":"20220320-171901_1247104049","dateCreated":"2022-03-21T23:56:14+0000","dateStarted":"2022-03-21T23:56:40+0000","dateFinished":"2022-03-21T23:57:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:254"},{"text":"%livy2.pyspark\nimport locale\nlocale.setlocale(locale.LC_ALL,'en_US.UTF-8'); # set the encoding for UTF-8 functionality\nfrom pyspark.sql.functions import from_json, col, size, explode, lower, desc, when, isnull, log, to_date, to_timestamp, countDistinct, row_number, collect_list, concat_ws, udf\nfrom pyspark.sql import Window\nimport time\nspark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\nspark.conf.set(\"spark.sql.adaptive.skewJoin.enabled\", \"true\")\nspark.conf.set(\"spark.default.parallelism\",500)\nspark.conf.set(\"spark.sql.shuffle.partitions\", 1000)","user":"anonymous","dateUpdated":"2022-03-21T23:56:33+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647903470178_0004<br/>Spark WebUI: <a href=\"http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/\">http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/</a>"}]},"apps":[],"jobName":"paragraph_1647906974465_-537643599","id":"20220320-181416_1283187381","dateCreated":"2022-03-21T23:56:14+0000","dateStarted":"2022-03-21T23:56:33+0000","dateFinished":"2022-03-21T23:56:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:255"},{"text":"%livy2.pyspark\ndf_ref = df_Raw\ncolumns = df_ref.columns\n\n#find the contact tweet\ndf_contact = df_ref.filter(~(isnull(df_ref.in_reply_to_user_id) & isnull(df_ref.retweeted_status)))\n\n#extract user id from user\ndf_contact = df_contact.withColumn(\"user_id\", df_contact.user[\"id\"])\n\n#extract retweeted_user from retweeted_status\ndf_contact = df_contact.withColumn('retweeted_user', when(isnull(df_contact.retweeted_status), None).otherwise(df_contact.retweeted_status[\"user\"]))\n\n#extract retweeted_user_id from retweeted_user\ndf_contact = df_contact.withColumn('retweeted_user_id', when(isnull(df_contact.retweeted_user), None).otherwise(df_contact.retweeted_user[\"id\"]))\n\n#only keep id fields\ndf_contact = df_contact[[\"user_id\", \"in_reply_to_user_id\", \"retweeted_user_id\"]]\n\n#find the reply tweet, duplicate them, since they contribute 2 points to the score\ndf_reply = df_contact.filter(~isnull(df_contact.in_reply_to_user_id))","user":"anonymous","dateUpdated":"2022-03-21T23:56:42+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647903470178_0004<br/>Spark WebUI: <a href=\"http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/\">http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/</a>"}]},"apps":[],"jobName":"paragraph_1647906974466_1140586495","id":"20220320-215835_332326814","dateCreated":"2022-03-21T23:56:14+0000","dateStarted":"2022-03-21T23:56:42+0000","dateFinished":"2022-03-21T23:57:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:256"},{"text":"%livy2.pyspark\n#========================================================Interaction Score========================================================================#\ndf_contact_more_reply = df_contact.unionByName(df_reply)\n\n#combine in_reply_to_user_id with retweeted_user_id to form contact_user_id\ndf_contact_more_reply = df_contact_more_reply.withColumn('contact_user_id', when(isnull(df_contact_more_reply.retweeted_user_id), df_contact_more_reply.in_reply_to_user_id).otherwise(df_contact_more_reply.retweeted_user_id))[[\"user_id\", \"contact_user_id\"]]\n\n#find contact tweet involving only one user\ndf_contact_more_reply_self = df_contact_more_reply.filter(df_contact_more_reply.user_id == df_contact_more_reply.contact_user_id)\n\n#find contact tweet involving two users\ndf_contact_more_reply_other = df_contact_more_reply.filter(~(df_contact_more_reply.user_id == df_contact_more_reply.contact_user_id))\n\n#for row A, B, make a row B, A, since we want to store score between A and B two times to speed up query, no need to do this for contact tweet involving only one user\ndf_contact_more_reply_other_all = df_contact_more_reply_other.unionByName(df_contact_more_reply_other.rdd.toDF([\"contact_user_id\", \"user_id\"]))\n\n#glue contact user together\ndf_contact_all = df_contact_more_reply_other_all.unionByName(df_contact_more_reply_self)\n\n# PARTITION\ndf_contact_all = df_contact_all.repartition(1000, \"user_id\", \"contact_user_id\")\n\n#find the count\ndf_interaction = df_contact_all.groupby(\"user_id\", \"contact_user_id\").count()\n\n#compute the score\ndf_interaction_score = df_interaction.withColumn(\"interaction_score\", log(1 + df_interaction[\"count\"])).drop(\"count\")\n","user":"anonymous","dateUpdated":"2022-03-21T23:59:23+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647903470178_0004<br/>Spark WebUI: <a href=\"http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/\">http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/</a>"}]},"apps":[],"jobName":"paragraph_1647906974466_-1050254907","id":"20220320-151509_920033301","dateCreated":"2022-03-21T23:56:14+0000","dateStarted":"2022-03-21T23:59:23+0000","dateFinished":"2022-03-21T23:59:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:257"},{"text":"%livy2.pyspark\n# load in the raw Twitter data\nrawDf = df_Raw\n\n# load in the blacklist of popular hashtag\nrawPopular = sc.textFile(\"popular_hashtags.txt\")\npopular_tags = rawPopular.collect()\n\n# extract out the nested hashtag field from the entity field\ndf_hashtags_out = rawDf.withColumn(\"hashtags\", col(\"entities.hashtags\"))\n\n# explode out the hashtag list into individual hashtag\ndf_hashtags_explode = df_hashtags_out.withColumn(\"explode_tag\", explode(\"hashtags\"))\n\n# transform all tags to lower cases\ndf_hashtags_text = df_hashtags_explode.withColumn(\"tag_text\", lower(col(\"explode_tag.text\")))","user":"anonymous","dateUpdated":"2022-03-21T23:59:31+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647903470178_0004<br/>Spark WebUI: <a href=\"http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/\">http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/</a>"}]},"apps":[],"jobName":"paragraph_1647906974466_1008075120","id":"20220320-204839_1256238007","dateCreated":"2022-03-21T23:56:14+0000","dateStarted":"2022-03-21T23:59:31+0000","dateFinished":"2022-03-21T23:59:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:258"},{"text":"%livy2.pyspark\n#========================================================Hashtags Score========================================================================#\n# load in the raw Twitter data\nrawDf = df_Raw\n\n# load in the blacklist of popular hashtag\nrawPopular = sc.textFile(\"popular_hashtags.txt\")\npopular_tags = rawPopular.collect()\n\n# extract out the nested hashtag field from the entity field\ndf_hashtags_out = rawDf.withColumn(\"hashtags\", col(\"entities.hashtags\"))\n\n# explode out the hashtag list into individual hashtag\ndf_hashtags_explode = df_hashtags_out.withColumn(\"explode_tag\", explode(\"hashtags\"))\n\n# transform all tags to lower cases\ndf_hashtags_text = df_hashtags_explode.withColumn(\"tag_text\", lower(col(\"explode_tag.text\")))\n\n# rename to user_id\ndf_hash_tags_text_tags = df_hashtags_text\\\n            .withColumn(\"user_id\", col(\"user.id\"))\n            \n# select only relevant fields\ndf_tags = df_hash_tags_text_tags.select(col(\"user_id\"), col(\"tag_text\"))\n\n# filter out blacklist popular tags\ndf_tags_filtered = df_tags.filter(~col(\"tag_text\").isin(popular_tags))\n\n# each user's tag aggregate its count\ndf_tags_aggregate = df_tags_filtered.groupby(\"user_id\", \"tag_text\").count()\n\ndf_tags_aggregate_2 = df_tags_aggregate.withColumnRenamed(\"user_id\", \"user2_id\").withColumnRenamed(\"count\", \"count2\")\n\n# self-join to make userA-userB-totalCount\ndf_tag_crossjoin = df_tags_aggregate.join(df_tags_aggregate_2, \\\n                            (df_tags_aggregate_2.tag_text == df_tags_aggregate.tag_text) & (df_tags_aggregate_2.user2_id != df_tags_aggregate.user_id))\\\n                            .withColumn(\"count_sum\", col(\"count\") + col(\"count2\"))\n\ndf_tag_crossjoin = df_tag_crossjoin.repartition(1000, \"user_id\", \"user2_id\")\n# make the per user pair hashtag raw count sum                      \ndf_score2_raw =  df_tag_crossjoin.select(col(\"user_id\"), col(\"user2_id\"), col(\"count_sum\")).groupby(\"user_id\", \"user2_id\").sum(\"count_sum\")\\\n                    .withColumnRenamed(\"user2_id\", \"contact_user_id\")\\\n                    .withColumnRenamed(\"sum(count_sum)\", \"countSumRaw\")\n\n# filter out the self-hashtag case, leave it default to 1 so that later hashtag score would be 1                   \ndf_score2 =  df_score2_raw.filter(col(\"countSumRaw\") > 10)\\\n                .withColumn(\"hashtag_score\", 1 + log(1 + col(\"countSumRaw\") - 10))\\\n                .withColumn(\"user_id_hash\", col(\"user_id\"))\\\n                .withColumn(\"contact_user_id_hash\", col(\"contact_user_id\"))\n\n# calculate the hashtag score\ndf_hashtag_score = df_score2.select(col(\"user_id_hash\"), col(\"contact_user_id_hash\"), col(\"hashtag_score\"))\n","user":"anonymous","dateUpdated":"2022-03-21T23:59:57+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647903470178_0004<br/>Spark WebUI: <a href=\"http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/\">http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/</a>"}]},"apps":[],"jobName":"paragraph_1647906974467_-486207041","id":"20220320-151946_312750011","dateCreated":"2022-03-21T23:56:14+0000","dateStarted":"2022-03-21T23:59:57+0000","dateFinished":"2022-03-22T00:00:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:259"},{"text":"%livy2.pyspark\n#========================================================Join Interaction&Hashtag Score========================================================================#\n\ndf_product_join = df_interaction_score.join(df_hashtag_score,\\\n                        (df_interaction_score.user_id == df_hashtag_score.user_id_hash) & (df_interaction_score.contact_user_id == df_hashtag_score.contact_user_id_hash),\\\n                        how = \"left\")\ndf_product_score = df_product_join\\\n                    .withColumn(\"product_score\", \\\n                        when(isnull(df_product_join.hashtag_score), df_product_join.interaction_score)\\\n                            .otherwise(df_product_join.hashtag_score * df_product_join.interaction_score))\\\n                    .select(\"user_id\", \"contact_user_id\", \"product_score\")","user":"anonymous","dateUpdated":"2022-03-22T00:00:03+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647903470178_0004<br/>Spark WebUI: <a href=\"http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/\">http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/</a>"}]},"apps":[],"jobName":"paragraph_1647906974467_-1278179167","id":"20220320-151939_869361350","dateCreated":"2022-03-21T23:56:14+0000","dateStarted":"2022-03-22T00:00:03+0000","dateFinished":"2022-03-22T00:00:06+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:260"},{"text":"%livy2.pyspark\n#========================================================Latest Contact Tweet Between Users========================================================================#\n#read the dataset\ndf_ref = df_Raw\n\ndf_ref_clean = df_ref.withColumn(\"user_id\", df_ref.user[\"id\"]).withColumn(\"tweet_id\", col(\"id\")) \\\n               .withColumn(\"ts\", to_timestamp(col(\"created_at\"), \"EEE MMM dd HH:mm:ss Z yyyy\"))\n               \n#extract retweeted_user from retweeted_status\ndf_ref_clean = df_ref_clean.withColumn('retweeted_user', when(isnull(df_ref_clean.retweeted_status), None).otherwise(df_ref_clean.retweeted_status[\"user\"]))\n\n#extract retweeted_user_id from retweeted_user\ndf_ref_clean = df_ref_clean.withColumn('retweeted_user_id', when(isnull(df_ref_clean.retweeted_user), None).otherwise(df_ref_clean.retweeted_user[\"id\"]))[[\"user_id\", \"in_reply_to_user_id\", \"retweeted_user_id\", \"text\", \"ts\", \"tweet_id\"]]\n\ndf_reply = df_ref_clean.filter(~isnull(df_ref_clean.in_reply_to_user_id))\ndf_reply = df_reply.withColumn('contact_user_id', df_reply['in_reply_to_user_id'])[['user_id','contact_user_id', 'text', 'ts', 'tweet_id']]\n\n\n#find contact tweet involving only one user\ndf_reply_self = df_reply.filter(df_reply.user_id == df_reply.contact_user_id)\n\n#find contact tweet involving two users\ndf_reply_other = df_reply.filter(~(df_reply.user_id == df_reply.contact_user_id))\n\n#for row A, B, make a row B, A, since we want to store score between A and B two times to speed up query, no need to do this for contact tweet involving only one user\ndf_reply_all = df_reply_other.unionByName(df_reply_other.rdd.toDF(['contact_user_id', 'user_id', 'text', 'ts', 'tweet_id']))\n\n#glue contact user together\ndf_reply_all = df_reply_all.unionByName(df_reply_self)\n\n#PARTITION\ndf_reply_all = df_reply_all.repartition(\"user_id\", \"contact_user_id\")\nw = Window.partitionBy(\"user_id\", \"contact_user_id\").orderBy(col(\"ts\").desc(), col(\"tweet_id\").desc())\ndf_reply_latest = df_reply_all.withColumn('group_rowrank', row_number().over(w))\\\n                .filter(col(\"group_rowrank\") == 1)\\\n                .drop(\"group_rowrank\")\n    \ndf_reply_latest = df_reply_latest.withColumn(\"ts_reply\", df_reply_latest[\"ts\"]) \\\n                                .withColumn(\"id_reply\", df_reply_latest[\"tweet_id\"]) \\\n                                .withColumn(\"latest_reply\", df_reply_latest.text) \\\n                                .withColumn(\"user_id_reply\", df_reply_latest.user_id) \\\n                                .withColumn(\"contact_user_id_reply\", df_reply_latest.contact_user_id) \\\n                                .drop(\"ts\", \"tweet_id\", \"user_id\", \"contact_user_id\", \"text\")\n\n\ndf_retweet = df_ref_clean.filter(~isnull(df_ref_clean['retweeted_user_id']))\ndf_retweet = df_retweet.withColumn('contact_user_id', df_retweet['retweeted_user_id'])[['user_id','contact_user_id', 'text', 'ts', 'tweet_id']]\n\n\n#find contact tweet involving only one user\ndf_retweet_self = df_retweet.filter(df_retweet.user_id == df_retweet.contact_user_id)\n\n#find contact tweet involving two users\ndf_retweet_other = df_retweet.filter(~(df_retweet.user_id == df_retweet.contact_user_id))\n\n#for row A, B, make a row B, A, since we want to store score between A and B two times to speed up query, no need to do this for contact tweet involving only one user\ndf_retweet_all = df_retweet_other.unionByName(df_retweet_other.rdd.toDF(['contact_user_id', 'user_id', 'text', 'ts', 'tweet_id']))\n\n#PARTITION\ndf_retweet_all = df_retweet_all.repartition(\"user_id\", \"contact_user_id\")\n#glue contact user together\ndf_retweet_all = df_retweet_all.unionByName(df_retweet_self)\n\nw = Window.partitionBy(\"user_id\", \"contact_user_id\").orderBy(col(\"ts\").desc(), col(\"tweet_id\").desc())\ndf_retweet_latest = df_retweet_all.withColumn('group_rowrank', row_number().over(w))\\\n                .filter(col(\"group_rowrank\") == 1)\\\n                .drop(\"group_rowrank\")\n\n\n\ndf_retweet_latest = df_retweet_latest.withColumn(\"ts_retweet\", df_retweet_latest[\"ts\"]) \\\n                                .withColumn(\"id_retweet\", df_retweet_latest[\"tweet_id\"]) \\\n                                .withColumn(\"latest_retweet\", df_retweet_latest.text) \\\n                                .withColumn(\"user_id_retweet\", df_retweet_latest.user_id) \\\n                                .withColumn(\"contact_user_id_retweet\", df_retweet_latest.contact_user_id) \\\n                                .drop(\"ts\", \"tweet_id\", \"user_id\", \"contact_user_id\", \"text\")","user":"anonymous","dateUpdated":"2022-03-22T00:00:05+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647903470178_0004<br/>Spark WebUI: <a href=\"http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/\">http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/</a>"}]},"apps":[],"jobName":"paragraph_1647906974467_1182929517","id":"20220320-151949_168924594","dateCreated":"2022-03-21T23:56:14+0000","dateStarted":"2022-03-22T00:00:05+0000","dateFinished":"2022-03-22T00:00:10+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:261"},{"text":"%livy2.pyspark\nstatic_table = df_product_score.join(df_reply_latest, (df_interaction_score.user_id == df_reply_latest.user_id_reply) & (df_interaction_score.contact_user_id == df_reply_latest.contact_user_id_reply), how='left')\n                                \nstatic_table = static_table.join(df_retweet_latest, (static_table.user_id == df_retweet_latest.user_id_retweet) & (static_table.contact_user_id == df_retweet_latest.contact_user_id_retweet), how='left') \\\n                                .drop(\"user_id_reply\", \"contact_user_id_reply\", \"user_id_retweet\",\"contact_user_id_retweet\")\n\nstatic_table = static_table.withColumn(\"both_latest\",  \\\n                when(isnull(static_table.ts_retweet), static_table[\"latest_reply\"]) \\\n                    .otherwise(when(isnull(static_table.ts_reply), static_table[\"latest_retweet\"]) \\\n                        .otherwise(when(static_table.ts_reply > static_table.ts_retweet, static_table[\"latest_reply\"]) \\\n                            .otherwise(when(static_table.ts_reply < static_table.ts_retweet, static_table[\"latest_retweet\"]) \\\n                                .otherwise(when(static_table.id_reply < static_table.id_retweet, static_table[\"latest_retweet\"]) \\\n                                    .otherwise(static_table[\"latest_reply\"]) \\\n                                ) \\\n                            ) \\\n                        ) \\\n                    ) \\\n                )\\\n                .drop(\"interaction_score\", \"ts_reply\", \"id_reply\", \"ts_retweet\", \"id_retweet\", \"user_id_tweet\", \"contact_user_id_tweet\") \\\n                .fillna(value = \"\", subset = [\"latest_retweet\", \"latest_reply\"])","user":"anonymous","dateUpdated":"2022-03-22T00:00:09+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647903470178_0004<br/>Spark WebUI: <a href=\"http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/\">http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/</a>"}]},"apps":[],"jobName":"paragraph_1647906974468_497048487","id":"20220320-194219_1368245026","dateCreated":"2022-03-21T23:56:14+0000","dateStarted":"2022-03-22T00:00:09+0000","dateFinished":"2022-03-22T00:00:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:262"},{"text":"%livy2.pyspark\n#========================================================Export to CSV File========================================================================#\nimport csv\nfrom StringIO import StringIO\ndef csv_string_for_row(row):\n    sio = StringIO()\n    csv.writer(sio, quoting=csv.QUOTE_ALL).writerow([unicode(elem).encode('utf-8') for elem in row])\n    value = sio.getvalue()\n    sio.close()\n    return value\nstatic_table.rdd.map(csv_string_for_row).saveAsTextFile('old_static_table.csv')\n","user":"anonymous","dateUpdated":"2022-03-22T00:00:47+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647903470178_0004<br/>Spark WebUI: <a href=\"http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/\">http://hn1-ccmicr.ingcwsvwruiurg0ho2yqvpw5gg.bx.internal.cloudapp.net:8088/proxy/application_1647903470178_0004/</a>"}]},"apps":[],"jobName":"paragraph_1647906974468_1624505154","id":"20220320-152043_1036102372","dateCreated":"2022-03-21T23:56:14+0000","dateStarted":"2022-03-22T00:00:47+0000","dateFinished":"2022-03-22T00:30:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:263"},{"text":"%livy2.pyspark\n#========================================================User Table========================================================================#\nimport locale\nlocale.setlocale(locale.LC_ALL,'en_US.UTF-8'); # set the encoding for Lower() functionality\nfrom pyspark.sql.functions import from_json, col, size, explode, lower, desc, when, log, to_date, to_timestamp, countDistinct, row_number\nfrom pyspark.sql import Window\n\nrawDf = df_Raw\n\n# take out the sender's user information\nuserDf = rawDf\\\n    .withColumn(\"tweet_id\", col(\"id\"))\\\n    .withColumn(\"ts\", to_timestamp(col(\"created_at\"), \"EEE MMM dd HH:mm:ss Z yyyy\"))\\\n    .withColumn(\"user_id\", col(\"user.id\"))\\\n    .withColumn(\"latest_screen_name\", col(\"user.screen_name\"))\\\n    .withColumn(\"latest_description\", col(\"user.description\"))\\\n    .select(\"tweet_id\", \"ts\", \"user_id\", \"latest_screen_name\", \"latest_description\")\n\n# take out the optionally retweet information\nretweetUserDf = rawDf.filter(~isnull(col(\"retweeted_status\")))\\\n                    .withColumn(\"tweet_id\", col(\"retweeted_status.id\"))\\\n                    .withColumn(\"ts\", to_timestamp(col(\"created_at\"), \"EEE MMM dd HH:mm:ss Z yyyy\"))\\\n                    .withColumn(\"user_id\", col(\"retweeted_status.user.id\"))\\\n                    .withColumn(\"latest_screen_name\", col(\"retweeted_status.user.screen_name\"))\\\n                    .withColumn(\"latest_description\", col(\"retweeted_status.user.description\"))\\\n                    .select(\"tweet_id\", \"ts\", \"user_id\", \"latest_screen_name\", \"latest_description\")\n\n# replace NULL description by empty string\nuserDf = userDf.fillna(value = \"\", subset = [\"latest_description\"])\nretweetUserDf = retweetUserDf.fillna(value = \"\", subset = [\"latest_description\"])\n\n# union the two dataframe\ntotal_user = userDf.unionByName(retweetUserDf)\n\n# partition by user_id and take the latest information based on descending timestamp, and then tweet_id for breaking tie\nw = Window.partitionBy(\"user_id\").orderBy(col(\"ts\").desc(), col(\"tweet_id\").desc())\nuser_info = total_user\\\n                .withColumn('group_rowrank', row_number().over(w))\\\n                .filter(col(\"group_rowrank\") == 1)\\\n                .drop(\"group_rowrank\", \"tweet_id\", \"ts\")","user":"anonymous","dateUpdated":"2022-03-21T23:56:14+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647802397257_0014<br/>Spark WebUI: <a href=\"http://hn1-cloud.pn4kh1fcooyenmbbmfayomuvka.bx.internal.cloudapp.net:8088/proxy/application_1647802397257_0014/\">http://hn1-cloud.pn4kh1fcooyenmbbmfayomuvka.bx.internal.cloudapp.net:8088/proxy/application_1647802397257_0014/</a>"}]},"apps":[],"jobName":"paragraph_1647906974469_290818571","id":"20220320-152052_841981029","dateCreated":"2022-03-21T23:56:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:264"},{"text":"%livy2.pyspark\n#========================================================Export to CSV File========================================================================#\nimport csv\nfrom StringIO import StringIO\ndef csv_string_for_row(row):\n    sio = StringIO()\n    csv.writer(sio, quoting=csv.QUOTE_ALL).writerow([unicode(elem).encode('utf-8') for elem in row])\n    value = sio.getvalue()\n    sio.close()\n    return value\nuser_info.rdd.map(csv_string_for_row).saveAsTextFile('user_info.csv')\n","user":"anonymous","dateUpdated":"2022-03-21T23:56:14+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647802397257_0014<br/>Spark WebUI: <a href=\"http://hn1-cloud.pn4kh1fcooyenmbbmfayomuvka.bx.internal.cloudapp.net:8088/proxy/application_1647802397257_0014/\">http://hn1-cloud.pn4kh1fcooyenmbbmfayomuvka.bx.internal.cloudapp.net:8088/proxy/application_1647802397257_0014/</a>"}]},"apps":[],"jobName":"paragraph_1647906974469_-1731905908","id":"20220320-152054_1602739035","dateCreated":"2022-03-21T23:56:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:265"},{"text":"%livy2.pyspark\n#========================================================Dynamic Table========================================================================#\ndf_ref = df_Raw\n\n#find the contact tweet\ndf_contact = df_ref.filter(~(isnull(df_ref.in_reply_to_user_id) & isnull(df_ref.retweeted_status)))\n\n#extract user id from user\ndf_contact = df_contact.withColumn(\"user_id\", df_contact.user[\"id\"])\n\n#extract retweeted_user from retweeted_status\ndf_contact = df_contact.withColumn('retweeted_user', when(isnull(df_contact.retweeted_status), None).otherwise(df_contact.retweeted_status[\"user\"]))\n\n#extract retweeted_user_id from retweeted_user\ndf_contact = df_contact.withColumn('retweeted_user_id', when(isnull(df_contact.retweeted_user), None).otherwise(df_contact.retweeted_user[\"id\"]))\n\n#extract hashtag list\ndf_contact = df_contact.withColumn(\"hashTagList\", df_contact.entities[\"hashtags\"])\n\n# explode out the hashtag list into individual hashtag\ndf_contact_explode = df_contact.withColumn(\"explode_tag\", explode(\"hashTagList\"))\n\n# transform all tags to lower cases\ndf_contact_hashtag_text = df_contact_explode.withColumn(\"tag_text\", lower(df_contact_explode.explode_tag.text))\n\ndf_contact_hash_string = df_contact_hashtag_text.groupby(\"id\").agg(collect_list('tag_text').alias('tag_list')).withColumn(\"tags\", concat_ws(\"#\", col(\"tag_list\")))\n\ndf_content_tags = df_contact.join(df_contact_hash_string, 'id', 'left')[['user_id', 'in_reply_to_user_id', 'retweeted_user_id', 'text', \"tags\"]]\n\ndf_content_tags = df_content_tags.withColumn(\"contact_user_id\", when(isnull(df_content_tags.retweeted_user_id), df_content_tags.in_reply_to_user_id).otherwise(df_content_tags.retweeted_user_id))\n\ndf_content_tags = df_content_tags.withColumn(\"is_reply\", when(isnull(df_content_tags.retweeted_user_id), True).otherwise(False))\n\ndf_content_tags = df_content_tags[['user_id', 'contact_user_id', 'is_reply', 'text', \"tags\"]]\n\n#find contact tweet involving only one user\ndf_content_tags_self = df_content_tags.filter(df_content_tags.user_id == df_content_tags.contact_user_id)\n\n#find contact tweet involving two users\ndf_content_tags_other = df_content_tags.filter(~(df_content_tags.user_id == df_content_tags.contact_user_id))\n\ndf_content_tags_other_reverse = df_content_tags_other.rdd.toDF([\"contact_user_id\", \"user_id\", \"is_reply\", \"text\", \"tags\"])\n\n#for row A, B, make a row B, A, since we want to store score between A and B two times to speed up query, no need to do this for contact tweet involving only one user\ndf_content_tags_other_all = df_content_tags_other.unionByName(df_content_tags_other_reverse)\n\n#glue contact user together\ndf_content_tags_all = df_content_tags_other_all.unionByName(df_content_tags_self)\n\ndynamic_table = df_content_tags_all\\\n                .withColumnRenamed(\"user_id\", \"sender\")\\\n                .withColumnRenamed(\"contact_user_id\", \"receiver\")\\\n                .withColumnRenamed(\"text\", \"content\")\\\n                [[\"is_reply\", \"content\", \"tags\", \"sender\", \"receiver\"]]","user":"anonymous","dateUpdated":"2022-03-21T23:56:14+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647802397257_0014<br/>Spark WebUI: <a href=\"http://hn1-cloud.pn4kh1fcooyenmbbmfayomuvka.bx.internal.cloudapp.net:8088/proxy/application_1647802397257_0014/\">http://hn1-cloud.pn4kh1fcooyenmbbmfayomuvka.bx.internal.cloudapp.net:8088/proxy/application_1647802397257_0014/</a>"}]},"apps":[],"jobName":"paragraph_1647906974469_1447725144","id":"20220320-152055_2057850755","dateCreated":"2022-03-21T23:56:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:266"},{"text":"%livy2.pyspark\n#========================================================Export to CSV File========================================================================#\nimport csv\nfrom StringIO import StringIO\ndef csv_string_for_row(row):\n    sio = StringIO()\n    csv.writer(sio, quoting=csv.QUOTE_ALL).writerow([unicode(elem).encode('utf-8') for elem in row])\n    value = sio.getvalue()\n    sio.close()\n    return value\ndynamic_table.rdd.map(csv_string_for_row).saveAsTextFile('dynamic_table.csv')","user":"anonymous","dateUpdated":"2022-03-21T23:56:14+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr/>Spark Application Id: application_1647802397257_0014<br/>Spark WebUI: <a href=\"http://hn1-cloud.pn4kh1fcooyenmbbmfayomuvka.bx.internal.cloudapp.net:8088/proxy/application_1647802397257_0014/\">http://hn1-cloud.pn4kh1fcooyenmbbmfayomuvka.bx.internal.cloudapp.net:8088/proxy/application_1647802397257_0014/</a>"}]},"apps":[],"jobName":"paragraph_1647906974470_-1262052510","id":"20220320-152056_1270138001","dateCreated":"2022-03-21T23:56:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:267"},{"text":"%livy2.pyspark\n","user":"anonymous","dateUpdated":"2022-03-21T23:56:14+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1647906974470_1377234606","id":"20220320-180736_1221216514","dateCreated":"2022-03-21T23:56:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:268"}],"name":"Micro3","id":"2GZ4HU4G5","noteParams":{},"noteForms":{},"angularObjects":{"livy2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}